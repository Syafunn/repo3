{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP5tcO6g+VzkAL/nRRSoxj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Syafunn/repo3/blob/main/percobaan6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Meg66-wRbjFU",
        "outputId": "3e39b3fd-5ca2-4cb2-c095-0e49f5485029"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aa42ba35-fdd9-4825-9a11-e905bbbecce6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aa42ba35-fdd9-4825-9a11-e905bbbecce6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving FakeNewsNet.csv to FakeNewsNet.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Path ke file langsung\n",
        "file_path = 'FakeNewsNet.csv'\n",
        "\n",
        "# Baca CSV dan ambil kolom title sebagai headline\n",
        "headlines_df = pd.read_csv(file_path)\n",
        "all_headlines = list(headlines_df.title.values)\n",
        "\n",
        "print(f\"Jumlah headline: {len(all_headlines)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT0SMdGgb7SA",
        "outputId": "a92148a5-1fd6-4da8-8c0a-332672a17b45"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah headline: 23196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_headlines[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLwSHTiIcNhq",
        "outputId": "c735f7ba-0768-4bd4-9a83-1d870ab6ef5f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Kandi Burruss Explodes Over Rape Accusation on 'Real Housewives of Atlanta' Reunion (Video)\", \"People's Choice Awards 2018: The best red carpet looks\", \"Sophia Bush Sends Sweet Birthday Message to 'One Tree Hill' Co-Star Hilarie Burton: 'Breyton 4eva'\", 'Colombian singer Maluma sparks rumours of inappropriate relationship with AUNT', 'Gossip Girl 10 Years Later: How Upper East Siders Shocked the World and Changed Pop Culture Forever', 'Gwen Stefani Got Dumped by Blake Shelton Over \"Jealousy and Drama\" (EXCLUSIVE)', 'Broward County Sheriff Fired For Lying About Parkland', \"Amber Rose Shuts Down French Montana Dating Rumors, Calls Rapper Her 'Bruvaaa'\", \"Mindy Kaling makes first post-baby appearance at Disneyland with her 'Wrinkle in Time' co-stars\", 'Katharine McPhee Butchers Tony Nominations: “I Have Not Been Drinking”', '‘WAGS Miami’ Stars Ashley Nicole Roberts and Philip Wheeler Are Married', 'Mel Gibson: Hollywood Pedophiles Have Nowhere Left To Hide', 'Medium Tyler Henry Addresses The ‘Chilling’ Messages Kristin Cavallari’s Deceased Brother Expressed During Reading', 'DWTS Season 27 Results: Week 5 - Disney Night', '2011 via CQ subscribers only Tax Foundation', '5 Reasons Why Tarek El Moussa Will Overcome His Latest Back Injury', 'David Cassidy cuts estranged daughter Katie completely out of his will… but leaves £110,000 to son Beau', 'Actress Brigitte Nielsen, 54, has given birth to her fifth child', 'The Kardashians donate whopping sum to Las Vegas mass shooting victims', 'Is Brad Pitt Open To Getting Back Together With Angelina After Rumors She’s Into It?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_headlines[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUoP_Y-EcV4C",
        "outputId": "80e0be97-7f5f-42cd-8f3c-b9661ad0d5db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Kandi Burruss Explodes Over Rape Accusation on 'Real Housewives of Atlanta' Reunion (Video)\",\n",
              " \"People's Choice Awards 2018: The best red carpet looks\",\n",
              " \"Sophia Bush Sends Sweet Birthday Message to 'One Tree Hill' Co-Star Hilarie Burton: 'Breyton 4eva'\",\n",
              " 'Colombian singer Maluma sparks rumours of inappropriate relationship with AUNT',\n",
              " 'Gossip Girl 10 Years Later: How Upper East Siders Shocked the World and Changed Pop Culture Forever',\n",
              " 'Gwen Stefani Got Dumped by Blake Shelton Over \"Jealousy and Drama\" (EXCLUSIVE)',\n",
              " 'Broward County Sheriff Fired For Lying About Parkland',\n",
              " \"Amber Rose Shuts Down French Montana Dating Rumors, Calls Rapper Her 'Bruvaaa'\",\n",
              " \"Mindy Kaling makes first post-baby appearance at Disneyland with her 'Wrinkle in Time' co-stars\",\n",
              " 'Katharine McPhee Butchers Tony Nominations: “I Have Not Been Drinking”',\n",
              " '‘WAGS Miami’ Stars Ashley Nicole Roberts and Philip Wheeler Are Married',\n",
              " 'Mel Gibson: Hollywood Pedophiles Have Nowhere Left To Hide',\n",
              " 'Medium Tyler Henry Addresses The ‘Chilling’ Messages Kristin Cavallari’s Deceased Brother Expressed During Reading',\n",
              " 'DWTS Season 27 Results: Week 5 - Disney Night',\n",
              " '2011 via CQ subscribers only Tax Foundation',\n",
              " '5 Reasons Why Tarek El Moussa Will Overcome His Latest Back Injury',\n",
              " 'David Cassidy cuts estranged daughter Katie completely out of his will… but leaves £110,000 to son Beau',\n",
              " 'Actress Brigitte Nielsen, 54, has given birth to her fifth child',\n",
              " 'The Kardashians donate whopping sum to Las Vegas mass shooting victims',\n",
              " 'Is Brad Pitt Open To Getting Back Together With Angelina After Rumors She’s Into It?']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all headlines with the value of \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFlC30ltcY9X",
        "outputId": "ab03d565-3204-4559-a765-765bc52f27b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23196"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_headlines[:20]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEyF0NCYcbDi",
        "outputId": "234f3cd9-d231-427a-82f8-c8eca243296e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Kandi Burruss Explodes Over Rape Accusation on 'Real Housewives of Atlanta' Reunion (Video)\",\n",
              " \"People's Choice Awards 2018: The best red carpet looks\",\n",
              " \"Sophia Bush Sends Sweet Birthday Message to 'One Tree Hill' Co-Star Hilarie Burton: 'Breyton 4eva'\",\n",
              " 'Colombian singer Maluma sparks rumours of inappropriate relationship with AUNT',\n",
              " 'Gossip Girl 10 Years Later: How Upper East Siders Shocked the World and Changed Pop Culture Forever',\n",
              " 'Gwen Stefani Got Dumped by Blake Shelton Over \"Jealousy and Drama\" (EXCLUSIVE)',\n",
              " 'Broward County Sheriff Fired For Lying About Parkland',\n",
              " \"Amber Rose Shuts Down French Montana Dating Rumors, Calls Rapper Her 'Bruvaaa'\",\n",
              " \"Mindy Kaling makes first post-baby appearance at Disneyland with her 'Wrinkle in Time' co-stars\",\n",
              " 'Katharine McPhee Butchers Tony Nominations: “I Have Not Been Drinking”',\n",
              " '‘WAGS Miami’ Stars Ashley Nicole Roberts and Philip Wheeler Are Married',\n",
              " 'Mel Gibson: Hollywood Pedophiles Have Nowhere Left To Hide',\n",
              " 'Medium Tyler Henry Addresses The ‘Chilling’ Messages Kristin Cavallari’s Deceased Brother Expressed During Reading',\n",
              " 'DWTS Season 27 Results: Week 5 - Disney Night',\n",
              " '2011 via CQ subscribers only Tax Foundation',\n",
              " '5 Reasons Why Tarek El Moussa Will Overcome His Latest Back Injury',\n",
              " 'David Cassidy cuts estranged daughter Katie completely out of his will… but leaves £110,000 to son Beau',\n",
              " 'Actress Brigitte Nielsen, 54, has given birth to her fifth child',\n",
              " 'The Kardashians donate whopping sum to Las Vegas mass shooting victims',\n",
              " 'Is Brad Pitt Open To Getting Back Together With Angelina After Rumors She’s Into It?']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=None,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n',\n",
        "    lower=True,\n",
        "    split=' ',\n",
        "    char_level=False,\n",
        "    oov_token=None\n",
        ")"
      ],
      "metadata": {
        "id": "QWU1Jm-Ecd5r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Tokenize the words in our headlines\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_headlines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g_CatbKcgvN",
        "outputId": "bb7d59f1-c1a7-490d-93fa-f886e88a5c24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words:  24404\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\n",
        "print(subset_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PppfdgIcjYY",
        "outputId": "ccbd28a6-0b12-4a34-95b5-212ed42de89f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 6, 'man': 282, 'plan': 930}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acs7zWkIclpZ",
        "outputId": "bd42fe61-1a13-4b3f-e0f0-b22c368304ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6], [282], [6], [930], [6], [], []]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to sequence of tokens\n",
        "input_sequences = []\n",
        "for line in all_headlines:\n",
        "    # Convert our headline into a sequence of tokens\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Create a series of sequences for each headline\n",
        "    for i in range(1, len(token_list)):\n",
        "        partial_sequence = token_list[:i+1]\n",
        "        input_sequences.append(partial_sequence)\n",
        "\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\n",
        "input_sequences[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqV9gg78coNB",
        "outputId": "73585600-0183-4cfb-caf6-95bbdf23fa6a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['kandi burruss', 'kandi burruss explodes', 'kandi burruss explodes over', 'kandi burruss explodes over rape', 'kandi burruss explodes over rape accusation']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[4634, 5276],\n",
              " [4634, 5276, 3809],\n",
              " [4634, 5276, 3809, 43],\n",
              " [4634, 5276, 3809, 43, 1026],\n",
              " [4634, 5276, 3809, 43, 1026, 5277]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Determine max sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqz-Nt1actlR",
        "outputId": "a3c403da-31ba-4d6b-a022-f79fc10d4f32"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0, 4634, 5276], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictors are every word except the last\n",
        "predictors = input_sequences[:,:-1]\n",
        "# Labels are the last word\n",
        "labels = input_sequences[:,-1]\n",
        "labels[:5]\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThyK5obNcwbR",
        "outputId": "e2d70d77-a5b2-4605-c032-47a35bd9f8a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5276, 3809,   43, 1026, 5277], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ],
      "metadata": {
        "id": "U2HXLJ9Ucz44"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\n",
        "input_len = max_sequence_len - 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add input embedding layer\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "\n",
        "# Add LSTM layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxdAPZXkc1_I",
        "outputId": "712edd2f-056e-4068-8801-e215a895a8e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "3QsQnTlxc4s9",
        "outputId": "714dda12-489c-4778-962a-9bf12c1e69be"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "PFclO-hgc7Q0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dummy_predictors = np.random.rand(100, predictors.shape[1]).astype(np.float32)\n",
        "dummy_labels = np.random.rand(100, labels.shape[1]).astype(np.float32)\n",
        "\n",
        "model.fit(dummy_predictors, dummy_labels, epochs=3, batch_size=8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6avOSpN1c9Ym",
        "outputId": "47250c0c-9a9a-4eab-e50c-19370bcc4431"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - loss: 123286.1875\n",
            "Epoch 2/3\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 123366.9375\n",
            "Epoch 3/3\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 123355.7188\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5b19c67e50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import psutil\n",
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print(f\"Total RAM: {ram_gb:.2f} GB\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kZERyu_dA7C",
        "outputId": "43a59895-fc1a-4014-952c-87f07645e8a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total RAM: 13.61 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import backend as K\n",
        "import gc\n",
        "\n",
        "# Bersihkan memori\n",
        "K.clear_session()\n",
        "gc.collect()\n",
        "\n",
        "# Contoh data dummy\n",
        "num_samples = 10000\n",
        "num_features = 10\n",
        "num_classes = 3\n",
        "\n",
        "predictors = np.random.rand(num_samples, num_features).astype(np.float32)\n",
        "labels = np.random.randint(0, num_classes, size=(num_samples,))\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
        "\n",
        "# Buat dataset tf.data\n",
        "batch_size = 16\n",
        "dataset = tf.data.Dataset.from_tensor_slices((predictors, labels))\n",
        "dataset = dataset.shuffle(buffer_size=1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Model sederhana\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(num_features,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Training dengan dataset\n",
        "model.fit(dataset, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "MmRf3pZtdHKb",
        "outputId": "809970f5-33ab-4c54-abf9-23e2d7c17acd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,883\u001b[0m (11.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,883</span> (11.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,883\u001b[0m (11.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,883</span> (11.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3296 - loss: 1.1025\n",
            "Epoch 2/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3276 - loss: 1.0998\n",
            "Epoch 3/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3393 - loss: 1.0981\n",
            "Epoch 4/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3346 - loss: 1.0987\n",
            "Epoch 5/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3501 - loss: 1.0978\n",
            "Epoch 6/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3491 - loss: 1.0968\n",
            "Epoch 7/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.3522 - loss: 1.0970\n",
            "Epoch 8/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3485 - loss: 1.0963\n",
            "Epoch 9/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3592 - loss: 1.0958\n",
            "Epoch 10/10\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3563 - loss: 1.0952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5b16cdc0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_next_token(seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted_probs = model.predict(token_list, verbose=0)\n",
        "    predicted_class = np.argmax(predicted_probs, axis=-1)\n",
        "    return predicted_class[0]  # hasil berupa 1 angka token ID\n",
        ""
      ],
      "metadata": {
        "id": "jrQB4pl7dSVW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Contoh data: kumpulan kalimat untuk tokenizer\n",
        "texts = [\"today in new york\", \"hello world\", \"machine learning is fun\"]\n",
        "\n",
        "# Buat tokenizer dan fit di data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# Ubah kalimat input jadi sequence token angka\n",
        "sequence = tokenizer.texts_to_sequences([\"today in new york\"])\n",
        "\n",
        "# Padding/truncating supaya panjang sequence jadi 10 (sesuai input model)\n",
        "padded_seq = pad_sequences(sequence, maxlen=10, padding='pre')\n",
        "\n",
        "print(padded_seq.shape)  # (1, 10)\n",
        "\n",
        "# Lalu inputkan ke model\n",
        "prediction = model.predict(padded_seq)\n",
        "print(prediction)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWw6O6fudU2U",
        "outputId": "8660af24-8d52-45d3-9691-3777fa61a1ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 10)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
            "[[0.30996284 0.17347099 0.51656616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(padded_seq)  # shape (1, num_classes)\n",
        "predicted_index = prediction.argmax(axis=-1)[0]  # ambil kelas dengan prediksi tertinggi\n",
        "predicted_word = tokenizer.index_word.get(predicted_index, \"unknown\")\n",
        "print(predicted_word)\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyn75djydWy3",
        "outputId": "ce6a3859-987d-42a6-84da-c2c8ad24be90"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_headline(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        # Predict next token\n",
        "        prediction = predict_next_token(seed_text)\n",
        "        # Convert token to word\n",
        "        next_word = tokenizer.sequences_to_texts([[prediction]])[0]\n",
        "\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\n",
        "        seed_text += \" \" + next_word\n",
        "    # Return headline as title-case\n",
        "    return seed_text.title()"
      ],
      "metadata": {
        "id": "ffgxV7hWdYaq"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "def generate_headline(seed_text, next_words=5):\n",
        "    for _ in range(next_words):\n",
        "        # Tokenize seed_text jadi sequence angka\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        # Padding/truncating jadi panjang 10 sesuai model input\n",
        "        token_list = pad_sequences([token_list], maxlen=10, padding='pre', truncating='pre')\n",
        "        # Prediksi output (misal distribusi kelas kata)\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        # Ambil kelas dengan probabilitas tertinggi\n",
        "        predicted_index = np.argmax(predicted_probs, axis=-1)[0]\n",
        "        # Cari kata dari tokenizer index_word\n",
        "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "        # Tambah kata hasil prediksi ke seed_text\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n"
      ],
      "metadata": {
        "id": "8S1_N9Aldalz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_texts = [\n",
        "    'sophia bush sends',\n",
        "    'colombian singer maluma',\n",
        "    'gossip girl 10',\n",
        "    'people s choice',\n",
        "    'kandi burruss explodes'\n",
        "]\n",
        "\n",
        "for seed in seed_texts:\n",
        "    print(generate_headline(seed, next_words=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UYw95lNd2Fm",
        "outputId": "cb567f2b-d9ff-4313-baaa-7e0f447588e9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sophia bush sends in in in in \n",
            "colombian singer maluma in in in in \n",
            "gossip girl 10 in in in in \n",
            "people s choice in in in in \n",
            "kandi burruss explodes in in in in \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Wpxv4ad_ZD",
        "outputId": "246aa507-6cf7-422d-d92a-26b63455f716"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}